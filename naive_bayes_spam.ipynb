{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_email(txt):\n",
    "    import re \n",
    "    pattern = r\"[\\w\\-'\\$]+\"\n",
    "    return re.findall(pattern, txt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_email(email, dataholder):\n",
    "    words = parse_email(email)\n",
    "    for word in words:\n",
    "        dataholder[word] = dataholder.get(word, 0) + 1\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_probs(spamCounts, hamCounts):\n",
    "    spamTotal = sum(spamCounts.values())\n",
    "    hamTotal = sum(hamCounts.values())\n",
    "    spam_probs = {word: spamCounts[word]/spamTotal for word in spamCounts}\n",
    "    ham_probs = {word: hamCounts[word]/hamTotal for word in hamCounts}\n",
    "    return spam_probs, ham_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spam_filter(spamfile):\n",
    "    import csv\n",
    "    spam = {} # spam[word] = # of times word appears in spam email\n",
    "    ham = {} # ham[word] = # of times word appears in non-spam email\n",
    "    with open(spamfile, newline='') as csvfile:\n",
    "        spamreader = csv.reader(csvfile)\n",
    "        for row in spamreader:\n",
    "            txt = row[0]\n",
    "            add_email(txt, spam) if row[1] == '1' else add_email(txt, ham)\n",
    "    spam_probs, ham_probs = get_probs(spam, ham)\n",
    "    return spam_probs, ham_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_email_logits(emailtxt, spam_probs, ham_probs):\n",
    "    import math\n",
    "    spamTotal, hamTotal = sum(spam_probs.values()), sum(ham_probs.values()) # for smoothing\n",
    "    vocab_count = len(spam_probs) + len(ham_probs)\n",
    "    words = set(parse_email(emailtxt))\n",
    "    log_prob_spam = 0\n",
    "    log_prob_ham = 0\n",
    "    for word in words:\n",
    "        if word in spam_probs:\n",
    "            log_prob_spam += math.log(spam_probs[word])\n",
    "        else:\n",
    "            # laplace smoothing \n",
    "            log_prob_spam += math.log((1/(spamTotal + vocab_count + 1)))\n",
    "\n",
    "        if word in ham_probs:\n",
    "            log_prob_ham += math.log(1.2*ham_probs[word])\n",
    "        else:\n",
    "            # laplace smoothing \n",
    "            log_prob_ham += math.log(1.2*(1/(hamTotal + vocab_count + 1)))\n",
    "\n",
    "    return log_prob_spam, log_prob_ham"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_email(emailtxt, spam_probs, ham_probs):\n",
    "    import math\n",
    "    logit_spam, logit_ham = get_email_logits(emailtxt, spam_probs, ham_probs)\n",
    "\n",
    "    return 1 if logit_spam > logit_ham + math.log(1000) else 0\n",
    "            \n",
    "    # return 1 if log_prob_spam > log_prob_ham + math.log(1000) else 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_probs, ham_probs = get_spam_filter('emails.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of false positives = 129\n",
      "number of ground negatives = 4358\n",
      "total is 5726\n",
      "accuracy = 91.40761439049948\n",
      "false positives = 2.960073428178063\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "accuracy = 0\n",
    "total = 0\n",
    "negatives = 0\n",
    "false_positives = 0\n",
    "bad = []\n",
    "with open(\"emails.csv\", newline='') as csvfile:\n",
    "    spamreader = csv.reader(csvfile)\n",
    "    for row in spamreader:\n",
    "        if row[1] == '':\n",
    "            break\n",
    "        txt, y = row[0], int(row[1])\n",
    "        y_pred = classify_email(txt, spam_probs=spam_probs, ham_probs=ham_probs)\n",
    "        if y == y_pred:\n",
    "            accuracy += 1\n",
    "        if y == 0:\n",
    "            negatives += 1\n",
    "        if y == 0 and y_pred == 1:\n",
    "            false_positives += 1\n",
    "            bad.append(row[0])\n",
    "        total += 1\n",
    "        \n",
    "print(f'number of false positives = {false_positives}')\n",
    "print(f'number of ground negatives = {negatives}')\n",
    "print(f'total is {total}')\n",
    "print(f'accuracy = {accuracy/total * 100}')\n",
    "print(f'false positives = {false_positives/negatives * 100}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the following text was classified as spam when it is really not:\n",
      "Subject: folks ,  attached is a conservative ( and fairly rough ) estimate of the size of the  petrochemicals and refining market that is potentially exposed to prolonged  drought in southern texas which could result in extremely low riverflows and  possible curtailed production . the total annual revenue generated by these  assets is no less than $ 20 b and could be substantially higher as the  estimated capacity on some of these facilties is likely understated and other  facilties not yet identified are likely to be vulnerable .  note that this data does not include any facilities in the industrial  complexes from houston northward and eastward as they are much less likely to  experience such a drought - induced interruption . the only facilties  identified thus far lie on or near the following rivers : brazos , colorado ,  navidad , guadalupe , and nueces .  please let me know if you have any questions / comments as we work to determine  whether or not a low riverflow insurance product is viable .  thanks ,  charlie\n"
     ]
    }
   ],
   "source": [
    "txt = bad[2]\n",
    "print(f'the following text was classified as spam when it is really not:\\n{txt}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logit_spam=-968.0513427769715, \n",
      "logit_ham=-984.9200298850855\n"
     ]
    }
   ],
   "source": [
    "logit_spam, logit_ham = get_email_logits(txt, spam_probs=spam_probs, ham_probs=ham_probs)\n",
    "print(f'logit_spam={logit_spam}, \\nlogit_ham={logit_ham}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify_email(txt, spam_probs=spam_probs, ham_probs=ham_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
